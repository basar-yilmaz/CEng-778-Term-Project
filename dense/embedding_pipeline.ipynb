{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T13:52:04.790829Z",
     "start_time": "2024-12-28T13:52:04.774487Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from data path\n",
    "data_path = \"../data\"\n",
    "\n",
    "# load docs\n",
    "with open(f\"{data_path}/docs.pkl\", \"rb\") as f:\n",
    "    docs = pickle.load(f)\n",
    "\n",
    "# load queries\n",
    "with open(f\"{data_path}/queries.pkl\", \"rb\") as f:\n",
    "    queries = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 210158\n",
      "Number of queries: 150\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of documents: {len(docs)}\")\n",
    "print(f\"Number of queries: {len(queries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of GPUs available: 4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Load BERT model\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "model = torch.nn.DataParallel(model)  # Enable data parallelism\n",
    "model = model.to(device)  # Move model to GPUs\n",
    "\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_embed_texts(texts, tokenizer, model, batch_size=4096):\n",
    "    embeddings = []\n",
    "    for i in tqdm(\n",
    "        range(0, len(texts), batch_size), desc=\"Batch embedding\", unit=\"batch\"\n",
    "    ):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "        ).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu()\n",
    "        embeddings.extend(batch_embeddings)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def compute_similarity(query_embedding, doc_embedding):\n",
    "    return cosine_similarity(\n",
    "        query_embedding.unsqueeze(0), doc_embedding.unsqueeze(0)\n",
    "    ).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents: 210158\n",
      "number of documents: 210157\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of documents: {len(docs)}\")\n",
    "\n",
    "# Preprocess for empty query.query or empty doc.text\n",
    "empty_docs = [doc for doc in docs if doc.text == \"\" or doc.text is None]\n",
    "\n",
    "# Remove empty docs\n",
    "for doc in empty_docs:\n",
    "    docs.remove(doc)\n",
    "print(f\"number of documents: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch embedding: 100%|██████████| 52/52 [06:19<00:00,  7.31s/batch]\n",
      "Batch embedding: 100%|██████████| 1/1 [00:00<00:00,  8.42batch/s]\n"
     ]
    }
   ],
   "source": [
    "# Embed documents in batches\n",
    "doc_texts = [doc.text for doc in docs]\n",
    "doc_embeddings = batch_embed_texts(doc_texts, tokenizer, model)\n",
    "\n",
    "# Embed queries in batches\n",
    "query_texts = [query.query for query in queries]\n",
    "query_embeddings = batch_embed_texts(query_texts, tokenizer, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210157, 150)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_embeddings), len(query_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6789228916168213\n",
      "Doc: 35468:FT941-9178\t Similarity: 0.8791\n",
      "Doc: 154820:FT941-451\t Similarity: 0.8700\n",
      "Doc: 25759:FT942-5917\t Similarity: 0.8682\n",
      "Doc: 37007:FT941-13076\t Similarity: 0.8639\n",
      "Doc: 15490:FT944-9379\t Similarity: 0.8637\n",
      "Doc: 143993:FT932-7852\t Similarity: 0.8621\n",
      "Doc: 161869:FT932-11021\t Similarity: 0.8617\n",
      "Doc: 143323:FT943-2100\t Similarity: 0.8614\n",
      "Doc: 199180:FT942-2839\t Similarity: 0.8609\n",
      "Doc: 69284:FT944-7539\t Similarity: 0.8591\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(compute_similarity(query_embeddings[20], doc_embeddings[103216]))\n",
    "\n",
    "# calculate top 10 similar documents for query 321\n",
    "query_no = 20\n",
    "query_embedding = query_embeddings[query_no]\n",
    "similar_docs = []\n",
    "for idx, doc_embedding in enumerate(doc_embeddings):\n",
    "    similarity = compute_similarity(query_embedding, doc_embedding)\n",
    "    similar_docs.append((idx, similarity))\n",
    "\n",
    "# sort by similarity\n",
    "similar_docs = sorted(similar_docs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# get top 10\n",
    "top_10_docs = similar_docs[:10]\n",
    "\n",
    "for doc_no, similarity in top_10_docs:\n",
    "    print(f\"Doc: {doc_no}:{docs[doc_no].doc_no}\\t Similarity: {similarity:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
